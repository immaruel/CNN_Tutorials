{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0e03279686b3b8d4d34db62935c6ffaabb3e0b5b1fa0c9a858b6ef076aaf4b9ef",
   "display_name": "Python 3.7.10 64-bit ('pytorch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import copy \n",
    "from PIL import Image\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader 설정\n",
    "class CustomImageDataset(Dataset):\n",
    "    def read_data_set(self):\n",
    "\n",
    "        all_img_files = []\n",
    "        all_labels = []\n",
    "\n",
    "        class_names = os.walk(self.data_set_path).__next__()[1] \n",
    "\n",
    "        for index, class_name in enumerate(class_names):\n",
    "            label = index\n",
    "            img_dir = os.path.join(self.data_set_path, class_name)\n",
    "            img_files = os.walk(img_dir).__next__()[2]\n",
    "\n",
    "            for img_file in img_files:\n",
    "                img_file = os.path.join(img_dir, img_file)\n",
    "                img = Image.open(img_file)\n",
    "                if img is not None:\n",
    "                    all_img_files.append(img_file)\n",
    "                    all_labels.append(label) # label은 0 또는 1로 저장됨 (2개의 이미지폴더가 존재하므로)\n",
    "\n",
    "        return all_img_files, all_labels, len(all_img_files), len(class_names)\n",
    "\n",
    "    def __init__(self, data_set_path, transforms=None):\n",
    "        self.data_set_path = data_set_path\n",
    "        self.image_files_path, self.labels, self.length, self.num_classes = self.read_data_set()\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_files_path[index])\n",
    "        image = image.convert(\"RGB\") # Tesor는 RGB이므로 변환\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return {'image': image, 'label': self.labels[index]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([transforms.ToTensor(), # tensor형으로 바꾸기\n",
    "                                       transforms.Resize((32, 32)),\n",
    "                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_set = CustomImageDataset(data_set_path='data/cat_dog/training_set',transforms=transforms_train)\n",
    "train_loader = DataLoader(train_data_set, batch_size = 64, num_workers = 0, shuffle = True)\n",
    "\n",
    "test_data_set = CustomImageDataset(data_set_path='data/cat_dog/test_set',transforms=transforms_train)\n",
    "test_loader = DataLoader(test_data_set, batch_size = 64, num_workers = 0, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# train image 크기 확인\n",
    "train_data_set[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# test image 크기 확인\n",
    "test_data_set[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# train data set 크기 확인\n",
    "len(train_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# test data set 크기 확인\n",
    "len(test_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# train data 형태 확인\n",
    "type(train_data_set[0]['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# train data 형태 확인\n",
    "type(train_data_set[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features = 8 * 8 * 16, out_features = 64)\n",
    "        self.fc2 = nn.Linear(64,32)\n",
    "        self.fc3 = nn.Linear(32,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # input size = 32 x 32 x 3 -> 32 * 32 x 8 (가로, 세로 크기는 padding =1 을 주었으므로 불변 )\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x) # 32 x 32 x 8 -> 16 x 16 x 8\n",
    "\n",
    "        x = self.conv2(x) # 16 x 16 x 8 -> 16 x 16 x 16\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x) # 16 x 16 x 16 -> 8 x 8 x 16\n",
    "    \n",
    "        # fully-connected-layer에 넣기전 다시 한번 flatten 시키기\n",
    "        x = x.view(-1, 8 * 8 * 16)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "사용 :  cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU 활성화\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"사용 : \", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "사용된 모델 : CNN(\n  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=1024, out_features=64, bias=True)\n  (fc2): Linear(in_features=64, out_features=32, bias=True)\n  (fc3): Linear(in_features=32, out_features=10, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "# model 적용\n",
    "model = CNN().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "print(\"사용된 모델 :\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for i_batch, item in enumerate(train_loader):\n",
    "        image = item['image'].to(DEVICE)\n",
    "        label = item['label'].to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = F.cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i_batch % 100 == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(epoch, i_batch * len(image), len(train_loader.dataset), 100. * i_batch / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:28: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "Train Epoch: 1 [0/8000 (0%)]\tLoss: 0.581202\n",
      "Train Epoch: 1 [6400/8000 (80%)]\tLoss: 0.500652\n",
      "[Epoch 1]\n",
      "Train Epoch: 2 [0/8000 (0%)]\tLoss: 0.521500\n",
      "Train Epoch: 2 [6400/8000 (80%)]\tLoss: 0.575614\n",
      "[Epoch 2]\n",
      "Train Epoch: 3 [0/8000 (0%)]\tLoss: 0.494878\n",
      "Train Epoch: 3 [6400/8000 (80%)]\tLoss: 0.620357\n",
      "[Epoch 3]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer)\n",
    "    print(\"[Epoch {}]\".format(epoch))"
   ]
  }
 ]
}